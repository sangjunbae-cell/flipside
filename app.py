import streamlit as st
from youtube_transcript_api import YouTubeTranscriptApi
from langchain_openai import ChatOpenAI
from langchain_core.prompts import PromptTemplate
from langchain_community.tools.tavily_search import TavilySearchResults
import re

# --- í˜ì´ì§€ ì„¤ì • ---
st.set_page_config(page_title="InsightLens AI", page_icon="ğŸ•µï¸", layout="wide")

# --- CSS ì»¤ìŠ¤í…€ (UI í´ë¦¬ì‹±) ---
st.markdown("""
    <style>
    .main-header {font-size: 2.5rem; font-weight: 700; color: #1E3A8A;}
    .sub-header {font-size: 1.5rem; font-weight: 600; color: #4B5563;}
    .card {background-color: #f9fafb; padding: 20px; border-radius: 10px; border: 1px solid #e5e7eb; margin-bottom: 20px;}
    .fact-box {padding: 15px; border-radius: 8px; margin-bottom: 10px;}
    .fact-true {background-color: #ecfdf5; border-left: 5px solid #10b981;}
    .fact-check {background-color: #fff7ed; border-left: 5px solid #f97316;}
    </style>
""", unsafe_allow_html=True)

# --- ì‚¬ì´ë“œë°”: ëª¨ë“œ ì„ íƒ & ì„¤ì • ---
with st.sidebar:
    st.title("ğŸ•µï¸ InsightLens AI")
    st.markdown("---")
    mode = st.radio("ë¶„ì„ ëª¨ë“œ ì„ íƒ", ["ğŸ¥ ìœ íŠœë¸Œ ì˜ìƒ ë¶„ì„", "ğŸ“° ë‰´ìŠ¤ ê¸°ì‚¬ ë¶„ì„"])
    st.markdown("---")
    
    # Secretsì—ì„œ í‚¤ë¥¼ ë¨¼ì € ì°¾ì•„ë³´ê³ , ì—†ìœ¼ë©´ ì…ë ¥ì°½ì„ ë„ì›ë‹ˆë‹¤
    if "OPENAI_API_KEY" in st.secrets:
        openai_api_key = st.secrets["OPENAI_API_KEY"]
    else:
        openai_api_key = st.text_input("OpenAI API Key", type="password")

    if "TAVILY_API_KEY" in st.secrets:
        tavily_api_key = st.secrets["TAVILY_API_KEY"]
    else:
        tavily_api_key = st.text_input("Tavily API Key", type="password")
        
    st.info("ğŸ’¡ ì´ íˆ´ì€ AIì™€ ì‹¤ì‹œê°„ ê²€ìƒ‰(RAG)ì„ ê²°í•©í•˜ì—¬ ì½˜í…ì¸ ì˜ í¸í–¥ì„±ê³¼ ì‚¬ì‹¤ ì—¬ë¶€ë¥¼ ê²€ì¦í•©ë‹ˆë‹¤.")

# --- ê³µí†µ í•¨ìˆ˜ ---
def get_llm(openai_key):
    return ChatOpenAI(temperature=0, openai_api_key=openai_key, model_name="gpt-4o")

def get_search_tool(tavily_key):
    return TavilySearchResults(tavily_api_key=tavily_key, k=3)

# ---------------------------------------------------------
# ğŸ¥ ëª¨ë“œ 1: ìœ íŠœë¸Œ ë¶„ì„ ë¡œì§
# ---------------------------------------------------------
def run_youtube_analysis():
    st.markdown('<div class="main-header">ğŸ¥ ìœ íŠœë¸Œ íŒ©íŠ¸ì²´ì»¤</div>', unsafe_allow_html=True)
    
    url = st.text_input("ìœ íŠœë¸Œ ë§í¬ë¥¼ ì…ë ¥í•˜ì„¸ìš”", placeholder="https://youtu.be/...")
    
    if st.button("ì˜ìƒ ë¶„ì„ ì‹œì‘"):
        if not openai_api_key or not tavily_api_key:
            st.error("API Keyë¥¼ ë¨¼ì € ì…ë ¥í•´ì£¼ì„¸ìš”.")
            return
            
        # 1. ìë§‰ ì¶”ì¶œ
        video_id = None
        if "v=" in url:
            video_id = url.split("v=")[1].split("&")[0]
        elif "youtu.be" in url:
            video_id = url.split("/")[-1]
            
        if not video_id:
            st.error("ì˜¬ë°”ë¥´ì§€ ì•Šì€ ìœ íŠœë¸Œ ë§í¬ì…ë‹ˆë‹¤.")
            return

        try:
            with st.spinner("ìë§‰ì„ ë‹¤ìš´ë¡œë“œ ì¤‘ì…ë‹ˆë‹¤..."):
                transcript_list = YouTubeTranscriptApi.get_transcript(video_id, languages=['ko', 'en'])
                full_text = " ".join([t['text'] for t in transcript_list])[:4000] # ë¹„ìš© ì ˆê°ìš© ê¸¸ì´ ì œí•œ
        except Exception as e:
            st.error(f"ìë§‰ì„ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. (ì—ëŸ¬: {e})")
            return

        # 2. AI ë¶„ì„ (ì£¼ì¥ ì¶”ì¶œ -> ê²€ìƒ‰ -> ê²€ì¦)
        try:
            llm = get_llm(openai_api_key)
            search = get_search_tool(tavily_api_key)
            
            with st.spinner("ğŸ•µï¸â€â™€ï¸ AIê°€ ì˜ìƒì„ ì‹œì²­í•˜ê³  íŒ©íŠ¸ì²´í¬ë¥¼ ì§„í–‰ ì¤‘ì…ë‹ˆë‹¤..."):
                # A. í•µì‹¬ ì£¼ì¥ ì¶”ì¶œ
                claims_prompt = PromptTemplate.from_template("ë‹¤ìŒ í…ìŠ¤íŠ¸ì—ì„œ íŒ©íŠ¸ì²´í¬ê°€ í•„ìš”í•œ í•µì‹¬ ì£¼ì¥ 3ê°€ì§€ë§Œ ìš”ì•½í•´ì¤˜:\n{text}")
                claims = llm.invoke(claims_prompt.format(text=full_text)).content
                
                # B. ê²°ê³¼ ë¦¬í¬íŠ¸ ìƒì„±
                st.markdown("### ğŸ“Š ë¶„ì„ ë¦¬í¬íŠ¸")
                
                tab1, tab2 = st.tabs(["íŒ©íŠ¸ì²´í¬ ê²°ê³¼", "ì˜ìƒ ìš”ì•½"])
                
                with tab1:
                    # ê°„ë‹¨í•œ íŒŒì‹± í›„ ë£¨í”„
                    lines = [line for line in claims.split('\n') if line.strip()]
                    for line in lines:
                        if len(line) < 5: continue
                        
                        # ê²€ìƒ‰ ì‹¤í–‰
                        try:
                            search_result = search.invoke(line)
                            evidence = str(search_result)
                        except Exception:
                            evidence = "ê²€ìƒ‰ ì‹¤íŒ¨"
                        
                        # ìµœì¢… ê²€ì¦
                        verify_prompt = PromptTemplate.from_template(
                            "ì£¼ì¥: {claim}\nì¦ê±°: {evidence}\nìœ„ ì¦ê±°ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì£¼ì¥ì´ 'ì‚¬ì‹¤', 'ê±°ì§“', 'íŒë‹¨ë³´ë¥˜' ì¤‘ ë¬´ì—‡ì¸ì§€, ê·¸ë¦¬ê³  ê·¸ ì´ìœ ë¥¼ í•œ ë¬¸ì¥ìœ¼ë¡œ ì¨ì¤˜."
                        )
                        verdict = llm.invoke(verify_prompt.format(claim=line, evidence=evidence)).content
                        
                        # UI ì¶œë ¥
                        color_class = "fact-true" if "ì‚¬ì‹¤" in verdict else "fact-check"
                        st.markdown(f"""
                            <div class='fact-box {color_class}'>
                                <strong>ğŸ—£ï¸ ì£¼ì¥:</strong> {line}<br>
                                <strong>ğŸ¤– AI íŒì •:</strong> {verdict}
                            </div>
                        """, unsafe_allow_html=True)
                
                with tab2:
                    summary = llm.invoke(f"ë‹¤ìŒ ë‚´ìš©ì„ 3ì¤„ë¡œ ìš”ì•½í•´ì¤˜:\n{full_text}").content
                    st.info(summary)
        except Exception as e:
             st.error(f"ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")

# ---------------------------------------------------------
# ğŸ“° ëª¨ë“œ 2: ë‰´ìŠ¤ ê¸°ì‚¬ ë¶„ì„ ë¡œì§
# ---------------------------------------------------------
def run_news_analysis():
    st.markdown('<div class="main-header">ğŸ“° ë‰´ìŠ¤ ë”¥ë‹¤ì´ë¸Œ & í¸í–¥ì„± ë¶„ì„</div>', unsafe_allow_html=True)
    
    col1, col2 = st.columns([1, 1])
    with col1:
        headline = st.text_input("ê¸°ì‚¬ ì œëª© (Headline)")
    with col2:
        media_name = st.text_input("ì–¸ë¡ ì‚¬ëª… (ì„ íƒì‚¬í•­)")
        
    article_body = st.text_area("ê¸°ì‚¬ ë³¸ë¬¸ ë‚´ìš© (ì—¬ê¸°ì— ë¶™ì—¬ë„£ìœ¼ì„¸ìš”)", height=200)
    
    if st.button("ê¸°ì‚¬ ë¶„ì„ ì‹œì‘"):
        if not openai_api_key or not article_body:
            st.error("API Keyì™€ ë³¸ë¬¸ ë‚´ìš©ì€ í•„ìˆ˜ì…ë‹ˆë‹¤.")
            return

        try:
            llm = get_llm(openai_api_key)
            
            with st.spinner("ğŸ” ê¸°ì‚¬ì˜ í–‰ê°„ì„ ì½ê³  ëˆ„ë½ëœ ë§¥ë½ì„ ì°¾ëŠ” ì¤‘ì…ë‹ˆë‹¤..."):
                
                # 1. ìê·¹ì„± & í”„ë ˆì´ë° ë¶„ì„
                bias_prompt = PromptTemplate.from_template("""
                    ê¸°ì‚¬ ì œëª©: {headline}
                    ë³¸ë¬¸: {body}
                    
                    ì´ ê¸°ì‚¬ë¥¼ ë¶„ì„í•´ì„œ ë‹¤ìŒ 2ê°€ì§€ë¥¼ ì•Œë ¤ì¤˜:
                    1. ìê·¹ì„± ì ìˆ˜ (0~100ì )ì™€ ê·¸ ì´ìœ 
                    2. ì´ ê¸°ì‚¬ê°€ ë…ìì—ê²Œ ì‹¬ì–´ì£¼ë ¤ëŠ” í”„ë ˆì„(ì˜ë„)
                """)
                bias_result = llm.invoke(bias_prompt.format(headline=headline, body=article_body)).content
                
                # 2. ëˆ„ë½ëœ ë§¥ë½ ê²€ìƒ‰ (RAG)
                search = get_search_tool(tavily_api_key)
                context_query = llm.invoke(f"ì´ ê¸°ì‚¬ '{headline}'ì˜ ì£¼ì¥ì„ ë°˜ë°•í•˜ê±°ë‚˜ ë³´ì™„í•˜ê¸° ìœ„í•´ ê²€ìƒ‰í•´ì•¼ í•  í‚¤ì›Œë“œ 1ê°œë§Œ ì•Œë ¤ì¤˜.").content
                search_res = search.invoke(context_query)
                
                missing_context = llm.invoke(f"""
                    ê¸°ì‚¬ ë‚´ìš©: {article_body}
                    ê²€ìƒ‰ëœ ì™¸ë¶€ ì‚¬ì‹¤: {search_res}
                    
                    ìœ„ 'ê²€ìƒ‰ëœ ì™¸ë¶€ ì‚¬ì‹¤'ì—ëŠ” ìˆì§€ë§Œ, 'ê¸°ì‚¬ ë‚´ìš©'ì—ì„œëŠ” ì™ ë¹ ì ¸ìˆëŠ”(ëˆ„ë½ëœ) ì¤‘ìš”í•œ ë§¥ë½ 1ê°€ì§€ë§Œ ì°¾ì•„ì„œ ì„¤ëª…í•´ì¤˜.
                """).content

                # --- ê²°ê³¼ ì¶œë ¥ ---
                st.markdown("### âš–ï¸ ë¶„ì„ ê²°ê³¼")
                
                # ìê·¹ì„± ê²Œì´ì§€ (í…ìŠ¤íŠ¸ë¡œ í‘œí˜„)
                st.markdown(f"<div class='card'>{bias_result}</div>", unsafe_allow_html=True)
                
                st.markdown("### ğŸ§© ëˆ„ë½ëœ í¼ì¦ ì¡°ê° (Missing Context)")
                st.markdown(f"""
                    <div class='fact-box fact-check'>
                        <strong>âš ï¸ AIê°€ ì°¾ì€ ë¹ ì§„ ë§¥ë½:</strong><br>
                        {missing_context}
                    </div>
                """, unsafe_allow_html=True)
        except Exception as e:
            st.error(f"ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")

# --- ë©”ì¸ ì‹¤í–‰ ---
if mode == "ğŸ¥ ìœ íŠœë¸Œ ì˜ìƒ ë¶„ì„":
    run_youtube_analysis()
else:
    run_news_analysis()
