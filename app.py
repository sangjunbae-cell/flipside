import streamlit as st
from langchain_community.document_loaders import YoutubeLoader
from langchain_community.document_loaders import WebBaseLoader
from langchain_openai import ChatOpenAI
from langchain_core.prompts import PromptTemplate
from langchain_community.tools.tavily_search import TavilySearchResults
import re

# --- í˜ì´ì§€ ì„¤ì • ---
st.set_page_config(page_title="Veritas Lens", page_icon="ğŸ‘ï¸", layout="wide")

# --- CSS ì»¤ìŠ¤í…€ ---
st.markdown("""
    <style>
    .main-title {font-size: 3rem; font-weight: 800; color: #111827; letter-spacing: -0.05rem;}
    .sub-title {font-size: 1.2rem; color: #6B7280; margin-bottom: 2rem;}
    .card {background-color: #ffffff; padding: 25px; border-radius: 15px; box-shadow: 0 4px 6px -1px rgba(0, 0, 0, 0.1); margin-bottom: 20px;}
    .fact-box {padding: 15px; border-radius: 8px; margin-bottom: 10px; border-left-width: 5px;}
    .fact-true {background-color: #ecfdf5; border-color: #10b981; color: #065f46;}
    .fact-check {background-color: #fff7ed; border-color: #f97316; color: #9a3412;}
    .bias-gauge {font-size: 1.5rem; font-weight: bold; text-align: center; margin: 10px 0;}
    </style>
""", unsafe_allow_html=True)

# --- ì‚¬ì´ë“œë°”: API ì„¤ì • ---
with st.sidebar:
    st.header("âš™ï¸ Settings")
    if "OPENAI_API_KEY" in st.secrets:
        openai_api_key = st.secrets["OPENAI_API_KEY"]
    else:
        openai_api_key = st.text_input("OpenAI API Key", type="password")

    if "TAVILY_API_KEY" in st.secrets:
        tavily_api_key = st.secrets["TAVILY_API_KEY"]
    else:
        tavily_api_key = st.text_input("Tavily API Key", type="password")
        
    st.markdown("---")
    st.info("ğŸ‘ï¸ **Veritas Lens**ëŠ” URLì„ ë¶„ì„í•˜ì—¬ íŒ©íŠ¸ì™€ í¸í–¥ì„±ì„ ê¿°ëš«ì–´ ë´…ë‹ˆë‹¤.")

# --- ê³µí†µ í•¨ìˆ˜ ---
def get_llm(openai_key):
    return ChatOpenAI(temperature=0, openai_api_key=openai_key, model_name="gpt-4o")

def get_search_tool(tavily_key):
    return TavilySearchResults(tavily_api_key=tavily_key, k=3)

# ---------------------------------------------------------
# ğŸ§  ë¶„ì„ ë¡œì§ 1: ìœ íŠœë¸Œ (YoutubeLoader ì‚¬ìš©)
# ---------------------------------------------------------
def analyze_youtube(url, llm, search):
    # 1. ìë§‰ ì¶”ì¶œ (LangChain Loader ì‚¬ìš©)
    try:
        with st.spinner("ğŸ§ ì˜ìƒì˜ ìë§‰ì„ ì¶”ì¶œí•˜ê³  ìˆìŠµë‹ˆë‹¤..."):
            # ì–¸ì–´ ìš°ì„ ìˆœìœ„: í•œêµ­ì–´ -> ì˜ì–´ -> ë²ˆì—­ ì‹œë„
            loader = YoutubeLoader.from_youtube_url(
                url,
                add_video_info=False,
                language=["ko", "en"],
                translation="ko" 
            )
            docs = loader.load()
            full_text = docs[0].page_content[:6000]
            
    except Exception as e:
        st.error(f"âŒ ìë§‰ì„ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        st.warning(f"ì›ì¸: {e}")
        st.info("ğŸ’¡ íŒ: Streamlit Cloud ì„œë²„ IPê°€ ìœ íŠœë¸Œì— ì°¨ë‹¨ë˜ì—ˆì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ ê²½ìš° ë¡œì»¬(ë‚´ ì»´í“¨í„°)ì—ì„œ ì‹¤í–‰í•˜ë©´ í•´ê²°ë©ë‹ˆë‹¤.")
        return

    # 2. ë¶„ì„ ì‹œì‘
    with st.spinner("ğŸ‘ï¸ Veritas Lensê°€ ì˜ìƒì„ ë¶„ì„ ì¤‘ì…ë‹ˆë‹¤..."):
        analysis_prompt = PromptTemplate.from_template("""
        ë‹¤ìŒ ìœ íŠœë¸Œ ìŠ¤í¬ë¦½íŠ¸ë¥¼ ë¶„ì„í•´ì¤˜:
        
        [ìŠ¤í¬ë¦½íŠ¸]
        {text}
        
        [ìš”ì²­ì‚¬í•­]
        1. ì´ ì˜ìƒì˜ í•µì‹¬ ì£¼ì œë¥¼ 3ì¤„ë¡œ ìš”ì•½í•´ì¤˜.
        2. íŒ©íŠ¸ì²´í¬ê°€ í•„ìš”í•œ êµ¬ì²´ì ì¸ ì£¼ì¥(Fact Claims) 3ê°€ì§€ë§Œ ì¶”ì¶œí•´ì¤˜.
        
        í˜•ì‹:
        SUMMARY: ...
        CLAIMS:
        - ì£¼ì¥1
        - ì£¼ì¥2
        - ì£¼ì¥3
        """)
        
        analysis_result = llm.invoke(analysis_prompt.format(text=full_text)).content
        
        summary_text = ""
        claims_list = []
        
        if "SUMMARY:" in analysis_result and "CLAIMS:" in analysis_result:
            parts = analysis_result.split("CLAIMS:")
            summary_text = parts[0].replace("SUMMARY:", "").strip()
            claims_list = [c.strip("- ").strip() for c in parts[1].split("\n") if c.strip()]
        else:
            summary_text = analysis_result
            
        st.markdown(f"<div class='card'><h3>ğŸ“º ì˜ìƒ ìš”ì•½</h3>{summary_text}</div>", unsafe_allow_html=True)
        
        st.markdown("### ğŸ•µï¸ íŒ©íŠ¸ì²´í¬ ë¦¬í¬íŠ¸")
        for claim in claims_list:
            if len(claim) < 5: continue
            
            try:
                search_res = search.invoke(claim)
                evidence = str(search_res)
            except:
                evidence = "ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ"
            
            verify_prompt = PromptTemplate.from_template(
                "ì£¼ì¥: {claim}\nì¦ê±°: {evidence}\nì¦ê±°ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì´ ì£¼ì¥ì´ 'ì‚¬ì‹¤', 'ê±°ì§“', 'íŒë‹¨ë³´ë¥˜' ì¤‘ ë¬´ì—‡ì¸ì§€ íŒë‹¨í•˜ê³  ì´ìœ ë¥¼ 1ë¬¸ì¥ìœ¼ë¡œ ì¨ì¤˜."
            )
            verdict = llm.invoke(verify_prompt.format(claim=claim, evidence=evidence)).content
            
            color_class = "fact-true" if "ì‚¬ì‹¤" in verdict else "fact-check"
            st.markdown(f"<div class='fact-box {color_class}'><strong>ğŸ—£ï¸ {claim}</strong><br>â†³ {verdict}</div>", unsafe_allow_html=True)

# ---------------------------------------------------------
# ğŸ§  ë¶„ì„ ë¡œì§ 2: ì›¹ ë‰´ìŠ¤
# ---------------------------------------------------------
def analyze_article(url, llm, search):
    try:
        with st.spinner("ğŸ“° ê¸°ì‚¬ ë³¸ë¬¸ì„ ì½ì–´ì˜¤ëŠ” ì¤‘ì…ë‹ˆë‹¤..."):
            loader = WebBaseLoader(url)
            docs = loader.load()
            article_content = docs[0].page_content[:6000]
            article_title = docs[0].metadata.get('title', 'ì œëª© ì—†ìŒ')
    except Exception as e:
        st.error(f"ê¸°ì‚¬ë¥¼ ì½ì–´ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. (ì ‘ê·¼ ì°¨ë‹¨ ë˜ëŠ” ì˜ëª»ëœ URL): {e}")
        return

    with st.spinner("âš–ï¸ ê¸°ì‚¬ì˜ í¸í–¥ì„±ê³¼ ë§¥ë½ì„ ë¶„ì„ ì¤‘ì…ë‹ˆë‹¤..."):
        bias_prompt = PromptTemplate.from_template("""
        ê¸°ì‚¬ ì œëª©: {title}
        ê¸°ì‚¬ ë³¸ë¬¸: {text}
        
        ë‹¤ìŒ 3ê°€ì§€ë¥¼ ë¶„ì„í•´ì¤˜:
        1. ìê·¹ì„± ì ìˆ˜ (0~100ì )
        2. ì´ ê¸°ì‚¬ì˜ í”„ë ˆì´ë°(ì˜ë„) ìš”ì•½
        3. ì´ ê¸°ì‚¬ì˜ ì£¼ì¥ì„ ê²€ì¦í•˜ê¸° ìœ„í•´ ê²€ìƒ‰í•´ì•¼ í•  í‚¤ì›Œë“œ 1ê°œ
        
        í˜•ì‹:
        SCORE: ...
        FRAMING: ...
        KEYWORD: ...
        """)
        
        bias_res = llm.invoke(bias_prompt.format(title=article_title, text=article_content)).content
        
        score = "N/A"
        framing = "ë¶„ì„ ì‹¤íŒ¨"
        keyword = article_title
        
        for line in bias_res.split('\n'):
            if "SCORE:" in line: score = line.split(":")[1].strip()
            if "FRAMING:" in line: framing = line.split(":")[1].strip()
            if "KEYWORD:" in line: keyword = line.split(":")[1].strip()
            
        search_res = search.invoke(keyword)
        missing_context = llm.invoke(f"ê¸°ì‚¬ ë‚´ìš©: {article_content}\nì™¸ë¶€ ì‚¬ì‹¤: {search_res}\nê¸°ì‚¬ì—ì„œ ëˆ„ë½ëœ ì¤‘ìš”í•œ ë§¥ë½ 1ê°€ì§€ë§Œ ì°¾ì•„ì„œ ì„¤ëª…í•´ì¤˜.").content
        
        st.markdown(f"<div class='card'><h3>ğŸ“° {article_title}</h3></div>", unsafe_allow_html=True)
        col1, col2 = st.columns(2)
        with col1:
             st.markdown(f"<div class='card'><div class='bias-gauge'>ğŸ”¥ ìê·¹ì„± ì§€ìˆ˜: {score}</div></div>", unsafe_allow_html=True)
        with col2:
             st.markdown(f"<div class='card'><strong>ğŸ” í”„ë ˆì´ë°:</strong><br>{framing}</div>", unsafe_allow_html=True)
        st.markdown(f"<div class='fact-box fact-check'><strong>ğŸ§© ë†“ì¹œ ë§¥ë½(Missing Context):</strong><br>{missing_context}</div>", unsafe_allow_html=True)

# ---------------------------------------------------------
# ğŸš€ ë©”ì¸ ì‹¤í–‰ë¶€
# ---------------------------------------------------------
st.markdown('<div class="main-title">Veritas Lens <span style="font-size:1.5rem; color:#3B82F6;">Beta</span></div>', unsafe_allow_html=True)
st.markdown('<div class="sub-title">See the truth behind the noise. URL í•˜ë‚˜ë¡œ íŒ©íŠ¸ì™€ í¸í–¥ì„±ì„ ê¿°ëš«ì–´ ë³´ì„¸ìš”.</div>', unsafe_allow_html=True)

url_input = st.text_input("ğŸ”— ë¶„ì„í•˜ê³  ì‹¶ì€ ë§í¬ë¥¼ ì…ë ¥í•˜ì„¸ìš” (YouTube or News URL)", placeholder="https://...")

if st.button("Analyze Link ğŸš€"):
    if not url_input:
        st.warning("ë§í¬ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”!")
    elif not openai_api_key or not tavily_api_key:
        st.error("API Key ì„¤ì •ì´ í•„ìš”í•©ë‹ˆë‹¤ (ì‚¬ì´ë“œë°” í™•ì¸).")
    else:
        llm_instance = get_llm(openai_api_key)
        search_tool = get_search_tool(tavily_api_key)
        
        if "youtube.com" in url_input or "youtu.be" in url_input:
            analyze_youtube(url_input, llm_instance, search_tool)
        else:
            analyze_article(url_input, llm_instance, search_tool)
